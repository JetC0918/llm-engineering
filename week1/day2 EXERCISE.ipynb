{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can generate high-quality content such as articles, social media posts, product descriptions, and more. This can save time and resources for businesses, while maintaining consistency and quality.\n",
      "2. **Product Design**: Generative AI can create 3D models and designs for products, reducing the need for manual design and prototyping. This can speed up the product development process and improve the accuracy of designs.\n",
      "3. **Marketing Automation**: Generative AI can generate personalized marketing messages, emails, and ad copy, allowing businesses to automate their marketing efforts and personalize customer experiences.\n",
      "4. **Customer Service Chatbots**: Generative AI can power chatbots that can understand and respond to customer inquiries, providing 24/7 support and improving customer satisfaction.\n",
      "5. **Data Analysis**: Generative AI can analyze large datasets and identify patterns, trends, and insights that may not be apparent through traditional analysis methods.\n",
      "6. **Image and Video Generation**: Generative AI can generate images and videos for various applications such as advertising, entertainment, and education.\n",
      "7. **Predictive Maintenance**: Generative AI can predict equipment failures and recommend maintenance schedules, reducing downtime and improving overall efficiency.\n",
      "8. **Supply Chain Optimization**: Generative AI can analyze supply chain data and optimize logistics, inventory management, and shipping routes to reduce costs and improve delivery times.\n",
      "9. **Financial Analysis**: Generative AI can analyze financial data and identify trends, patterns, and insights that can inform investment decisions and risk management strategies.\n",
      "10. **Cybersecurity**: Generative AI can detect and respond to cyber threats in real-time, improving the overall security posture of businesses.\n",
      "11. **Virtual Assistants**: Generative AI can power virtual assistants that can understand and respond to user queries, providing personalized recommendations and suggestions.\n",
      "12. **E-learning and Education**: Generative AI can create personalized learning experiences, adaptive assessments, and educational content, improving student outcomes and engagement.\n",
      "13. **Creative Writing**: Generative AI can generate creative writing such as poetry, short stories, and scripts, allowing businesses to produce high-quality content quickly and efficiently.\n",
      "14. **Social Media Management**: Generative AI can analyze social media trends, sentiment, and engagement, providing insights for businesses to optimize their social media strategy.\n",
      "15. **Predictive Modeling**: Generative AI can build predictive models that forecast customer behavior, sales, and revenue, enabling businesses to make informed decisions.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as articles, blog posts, social media posts, and even entire books. This can help businesses save time and resources on content creation.\n",
      "2. **Product Design**: Generative AI can be used to design new products, such as fashion items, furniture, or even entire buildings. This can help businesses quickly create unique designs without the need for extensive human input.\n",
      "3. **Marketing and Advertising**: Generative AI can be used to generate personalized marketing messages, product recommendations, and even entire ad campaigns. This can help businesses tailor their messaging to specific customer segments.\n",
      "4. **Customer Service Chatbots**: Generative AI can be used to create chatbots that can understand and respond to customer inquiries in a more human-like way.\n",
      "5. **Data Analysis and Visualization**: Generative AI can be used to analyze large datasets and generate visualizations, such as charts and graphs, to help businesses gain insights into their data.\n",
      "6. **Predictive Maintenance**: Generative AI can be used to predict equipment failures and schedule maintenance tasks, reducing downtime and increasing overall efficiency.\n",
      "7. **Automated Testing**: Generative AI can be used to create automated tests for software applications, reducing the time and cost associated with manual testing.\n",
      "8. **Personalized Recommendations**: Generative AI can be used to generate personalized product recommendations based on customer behavior and preferences.\n",
      "9. **Creative Writing and Editing**: Generative AI can be used to assist with creative writing tasks such as scriptwriting, article writing, and even editing.\n",
      "10. **Business Process Automation**: Generative AI can be used to automate business processes, such as workflows, approvals, and document review.\n",
      "\n",
      "Some specific industries that are leveraging generative AI include:\n",
      "\n",
      "* Finance: Using generative AI to generate financial reports, predict market trends, and identify potential investment opportunities.\n",
      "* Healthcare: Using generative AI to analyze medical images, diagnose diseases, and develop personalized treatment plans.\n",
      "* Education: Using generative AI to create personalized learning materials, automate grading, and provide real-time feedback to students.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses in various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI-powered tools can generate high-quality content such as blog posts, social media posts, product descriptions, and more, freeing up human writers' time.\n",
      "2. **Customer Service Chatbots**: Generative AI can power chatbots that provide 24/7 customer support, helping businesses handle a large volume of inquiries and improving customer experience.\n",
      "3. **Data Generation**: AI can generate synthetic data for testing and training machine learning models, reducing the need for human-annotated datasets and speeding up development cycles.\n",
      "4. **Marketing Automation**: Generative AI can create personalized marketing campaigns, including subject lines, emails, and ad copy, to improve email open rates and conversion rates.\n",
      "5. **Creative Design**: AI-powered design tools can generate new product designs, logos, and packaging concepts, streamlining the design process for businesses.\n",
      "6. **Sales Replication**: Generative AI can create sales scripts, personalized pitches, and proposals, enabling businesses to automate their sales processes and improve conversion rates.\n",
      "7. **Product Recommendation Systems**: AI can suggest personalized products based on customer behavior, purchase history, and search queries, enhancing the user experience and increasing sales.\n",
      "8. **Supply Chain Management**: Generative AI can optimize supply chain logistics, predict demand, and identify bottlenecks, reducing inventory costs and improving delivery times.\n",
      "9. **Language Translation**: AI-powered translation tools can translate written content, speech, and even entire conversations in real-time, breaking language barriers for businesses operating globally.\n",
      "10. **Quality Control**: Generative AI can analyze and detect defects in products, such as medical devices or automotive parts, reducing the risk of recalls and improving product quality.\n",
      "\n",
      "Some companies that are already leveraging generative AI in various business applications include:\n",
      "\n",
      "* Google (Google Assistant, Google Translate)\n",
      "* Facebook (Grapheme-to-Word Neural Network for generating text)\n",
      "* Amazon (AI-powered chatbots for customer support)\n",
      "* SAP (Generative AI for creating personalized product recommendations)\n",
      "* IBM (Watson Studio for building and deploying AI models)\n",
      "\n",
      "Businesses that successfully adopt generative AI will be able to:\n",
      "\n",
      "* Automate repetitive tasks and free up human resources\n",
      "* Improve customer experience and engagement\n",
      "* Generate high-quality content at scale\n",
      "* Optimize operations and reduce costs\n",
      "* Differentiate themselves from competitors through innovative solutions\n",
      "\n",
      "However, adopting generative AI also comes with challenges, such as ensuring data quality, addressing bias in AI models, and regulating the use of AI-generated content.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling aabd4debf0c8: 100% ▕██████████████████▏ 1.1 GB                         \u001b[K\n",
      "pulling c5ad996bda6e: 100% ▕██████████████████▏  556 B                         \u001b[K\n",
      "pulling 6e4c38e1172f: 100% ▕██████████████████▏ 1.1 KB                         \u001b[K\n",
      "pulling f4d24e9138dd: 100% ▕██████████████████▏  148 B                         \u001b[K\n",
      "pulling a85fe2a2e58e: 100% ▕██████████████████▏  487 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to understand what an LLM is, but since I don't know much about it, I'll just start from the basics. The user asked about a few key concepts: neural networks, attention mechanisms, and transformers. Let me think through this step by step.\n",
      "\n",
      "First, a neural network. From what I remember, neural networks are a type of machine learning model. They're inspired by the human brain's structure and function. So they have layers of nodes (which are like neurons) that process information. These nodes use some kind of activation function to make decisions during processing. The parts like weights and biases adjust themselves to improve performance, right? And they don't need a lot of data but can learn complex patterns from scratch.\n",
      "\n",
      "Wait, what about deep learning then? Oh yeah, neural networks are part of deep learning, which is machine learning using hierarchical or multi-layered models. That makes sense because the human brain processes information in multiple layers. So an LLM uses these neural networks to do something specific—like language processing tasks.\n",
      "\n",
      "Now, attention and transformers. The user mentioned those as core concepts, so I need to break them down too. Let me start with attention first. From what I remember, attention allows models to focus on specific parts of the input when making predictions or decisions. It's like paying attention to relevant words versus looking at irrelevant ones.\n",
      "\n",
      "So how is that achieved? Well, in the neural network model called BERT (which stands forBidirectional Efficiently Trained Language Model), each word has self-attention and cross-attention layers. Self-attention means a token looks at itself and others across the same sentence to determine what's relevant, while cross-attention uses surrounding context tokens. This helps the model understand the relevance of words in a given context.\n",
      "\n",
      "But how exactly is this computed? Oh right, it's done through matrices that calculate attention weights and feature vectors for each word. For example, each token has two probability matrices—one computing its own features (self-attention) and another with neighbors (cross-attention). Then these vectors are combined to produce a contextualized vector for the entire sentence.\n",
      "\n",
      "Moving on to transformers. Transformers are a type of neural network architecture that excels in processing sequential data, like text. Unlike traditional methods that use layers between layers, transformers don't rely on hidden layers, which makes them more memory-efficient and scalable.\n",
      "\n",
      "So how do they work? It has multiple blocks where each block consists of self-attention and feed-forward layers. The self-attention layer processes the input to create contextualized vectors, similar to what I thought about in BERT. Then these vectors are fed into a feed-forward network which does something more computation. This process allows transformers to capture long-range dependencies in sequences because they can look at all preceding tokens through the attention mechanism when combined with the sequential processing.\n",
      "\n",
      "Putting it together: An LLM uses attention to focus on relevant parts of input data and transformer components (like self-attention blocks and feed-forward layers) to efficiently process entire sequences. These mechanisms allow models like BERT or GPT-3 to perform complex tasks such as text understanding, answering questions, and even generating new text.\n",
      "\n",
      "But wait, isn't the user talking about LLMs in general? So what's an LLM? From the definitions, I can see that it's a model that learns from data without being explicitly programmed. It's used for various tasks like language modeling, question-answering, and simulation. So neural networks are foundational to these models because their layered structure allows them to process information in different dimensions and capture higher-level patterns.\n",
      "\n",
      "I also remember hearing about the transformer architecture specifically being crucial for success in NLP tasks due to its self-attention mechanism. Without transformers, achieving performance might require more manual feature engineering. So the combination of neural networks within the transformer framework is what makes LLMs so effective at understanding language and data structures.\n",
      "\n",
      "Another point is that these models are trained by minimizing prediction errors between their outputs and the actual results. This process involves backpropagation to adjust the model's weights, ensuring they perform optimally in various contexts given enough training data.\n",
      "\n",
      "In summary, an LLM leverages neural networks with attention to focus on relevant inputs through self-attention, and transformers enhance this by incorporating sequence processing abilities within their architecture. Together, these components enable sophisticated language understanding and generation.\n",
      "</think>\n",
      "\n",
      "An Language Model (LLM) is a machine learning model that learns from data without explicit programming. It uses these models, particularly neural networks with attention mechanisms like the Transformer, to perform tasks such as text comprehension, answering questions, and generating new text.\n",
      "\n",
      "**Key Components of LLMs:**\n",
      "\n",
      "1. **Neural Networks**: \n",
      "   - Neural networks are composed of layers (like in a deep learning setup) that process information similarly to biological neurons. They compute activation functions during processing and adjust weights and biases based on error gradients through backpropagation.\n",
      "\n",
      "2. **Attention Mechanisms**:\n",
      "   - Attention enables models to focus on specific input parts when making predictions or decisions.\n",
      "   - For example, in BERT's model, attention is computed using self-attention (tokens consider themselves and others) and cross-attention (previous context tokens).\n",
      "\n",
      "3. **Transformers**:\n",
      "   - Transimers efficient process sequential data by eliminating hidden layers, enabling scalability and efficiency.\n",
      "   - Transformers consist of self-attention blocks to create contextual vectors and feed-forward layers for further computation.\n",
      "\n",
      "Together, these components allow LLMs to effectively analyze language via self-attention in attention modules and sequence processing through transformers, leading to tasks like text understanding, answering, and generation.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__ (self,url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers = headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e97a1938-63f3-41e9-a6fe-f3abe013e39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f7fddda-4317-48b4-b58f-41d61f17c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define system prompt\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "    You are an assistantn that analyzes the contents of a website and provides\n",
    "    a short summary, ignoring text that might be navigation related.\n",
    "    Respond in markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ec1a392-0dda-47ef-a626-78f484074887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\"\"\n",
    "    \\nThe contents of this website is as follows; \\\n",
    "    please provide a short summary of this website in markdown. \\\n",
    "    If it includes news or announcements, then summarize these too.\\n\\n\n",
    "    \"\"\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "532fa4ab-b77f-4cfc-9023-b6b0147cc458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled Home - Edward Donner\n",
      "    \n",
      "The contents of this website is as follows;     please provide a short summary of this website in markdown.     If it includes news or announcements, then summarize these too.\n",
      "\n",
      "\n",
      "    Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d4eec47-b83e-4f8a-b5e1-65ed412f12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\":\"system\", \"content\":system_prompt},\n",
    "        {\"role\":\"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cf85b81-82b7-423e-9c65-e5c66f02e586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\n    You are an assistantn that analyzes the contents of a website and provides\\n    a short summary, ignoring text that might be navigation related.\\n    Respond in markdown.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Home - Edward Donner\\n    \\nThe contents of this website is as follows;     please provide a short summary of this website in markdown.     If it includes news or announcements, then summarize these too.\\n\\n\\n    Home\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nMay 28, 2025\\nConnecting my courses – become an LLM expert and leader\\nMay 18, 2025\\n2025 AI Executive Briefing\\nApril 21, 2025\\nThe Complete Agentic AI Engineering Course\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ebb2a97-962a-40ea-bd6d-183709cb370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model = \"llama3.2\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8e1b7b9-bcf6-4ad3-8c1a-295dc7f6e921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Website Summary\\n#### **Summary**\\n\\nThe website \"Home - Edward Donner\" is a personal website of Edward Donner, the co-founder and CTO of Nebula.io. The site focuses on promoting his work in applying AI to help people discover their potential.\\n\\n#### **News/Announcements**\\n* Upcoming Course: *\"Connecting my courses – become an LLM expert and leader\"*\\n* Recent Events:\\n\\t+ *\"2025 AI Executive Briefing\"\\'\\n\\t+ *\"The Complete Agentic AI Engineering Course\"`\\n    *-\"LLM Workshop – Hands-on with Agents – resources\"`\\n\\n#### **Website Section Summary**\\n\\nThere are no navigation-related sections, instead:\\n- A brief introduction to Edward Donner and his role as the co-founder of Nebula.io,\\n- An update on his previous work at untapt (acquired in 2021),\\n- Links to various social media profiles (LinkedIn, Twitter, Facebook) and an email newsletter subscription form.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e0252a0-847c-426b-9dcd-1d0b6b4fdb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46ab684f-bc91-4a8c-8642-8431b38085f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Website Summary\n",
       "\n",
       "**Edward Donner's Home Website**\n",
       "=====================================\n",
       "\n",
       "This website belongs to Edward Donner, a co-founder and CTO of Nebula.io. The website provides an overview of his work in applying AI to help people discover their potential.\n",
       "\n",
       "### Notable Features\n",
       "\n",
       "* **LLM Arena**: A section featuring Outsmart, an arena where LLMs compete against each other in a battle of diplomacy and deviousness.\n",
       "* **About Me**: Edward shares his interests, experience, and background in the field of AI and entrepreneurship.\n",
       "* **News and Announcements**:\n",
       "\t+ Upcoming courses: \"Connecting my courses – become an LLM expert and leader\"\n",
       "\t+ Past events: 2025 AI Executive Briefing\n",
       "\t+ Product announcements: Nebula.io's proprietary LLM matching model has received press coverage.\n",
       "\n",
       "### Contact Information\n",
       "\n",
       "* Email: [ed at] edwarddonner [dot] com\n",
       "* Website: www.edwarddonner.com\n",
       "* Social Media: LinkedIn, Twitter, Facebook"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d13dd1-06ba-4473-95e2-800a02a34417",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
